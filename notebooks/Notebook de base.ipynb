{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9771349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import classification_report, f1_score, precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f44a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dtypes = {\n",
    "    \"place\":\"category\",\n",
    "    \"catu\":\"category\",\n",
    "    \"grav\":\"category\",\n",
    "    \"sexe\":\"category\",\n",
    "    \"trajet\":\"category\",\n",
    "    \"locp\":\"category\",\n",
    "    \"actp\":\"category\",\n",
    "    \"etatp\":\"category\",\n",
    "    \"secuUn\":\"category\",\n",
    "    \"secuDeux\":\"category\",\n",
    "    \"tranches_ages\":\"category\",\n",
    "    \"catr\":\"category\",\n",
    "    \"circ\":\"category\",\n",
    "    \"vosp\":\"category\",\n",
    "    \"prof\":\"category\",\n",
    "    \"plan\":\"category\",\n",
    "    \"surf\":\"category\",\n",
    "    \"infra\":\"category\",\n",
    "    \"situ\":\"category\",\n",
    "    \"senc\":\"category\",\n",
    "    \"obs\":\"category\",\n",
    "    \"obsm\":\"category\",\n",
    "    \"choc\":\"category\",\n",
    "    \"manv\":\"category\",\n",
    "    \"catv_Label\":\"category\",\n",
    "    \"lum\":\"category\",\n",
    "    \"agg\":\"category\",\n",
    "    \"int\":\"category\",\n",
    "    \"atm\":\"category\",\n",
    "    \"col\":\"category\",\n",
    "    \"jour_de_la_semaine\":\"category\",\n",
    "    \"heure\":\"category\",\n",
    "    \"dep\": \"category\"\n",
    "    }\n",
    "df = pd.read_csv(r\"C:\\Users\\maill\\Documents\\GitHub\\SARA\\data\\fusion3.csv\", low_memory=False)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df = df.drop(['Unnamed: 0','num_acc','an_nais','an_naiss','age_acc_an','num_veh','senc','occutc','permis','secuDeux','date','com'], axis=1)\n",
    "df['place'] = df['place'].astype('object')\n",
    "df['dep'] = df['dep'].replace({'2A':201,'2B':202})\n",
    "df['dep'] = df['dep'].astype('int64')\n",
    "                               \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c070cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2291745 entries, 0 to 2291796\n",
      "Data columns (total 34 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   place               object \n",
      " 1   catu                object \n",
      " 2   grav                object \n",
      " 3   sexe                object \n",
      " 4   trajet              object \n",
      " 5   locp                object \n",
      " 6   actp                object \n",
      " 7   etatp               object \n",
      " 8   secuUn              object \n",
      " 9   tranches_ages       object \n",
      " 10  catr                object \n",
      " 11  circ                object \n",
      " 12  nbv                 float64\n",
      " 13  vosp                object \n",
      " 14  prof                object \n",
      " 15  plan                object \n",
      " 16  surf                object \n",
      " 17  infra               object \n",
      " 18  situ                object \n",
      " 19  obs                 object \n",
      " 20  obsm                object \n",
      " 21  choc                object \n",
      " 22  manv                object \n",
      " 23  catv_Label          object \n",
      " 24  lum                 object \n",
      " 25  agg                 object \n",
      " 26  int                 object \n",
      " 27  atm                 object \n",
      " 28  col                 object \n",
      " 29  dep                 int32  \n",
      " 30  jour_de_la_semaine  object \n",
      " 31  heure               int64  \n",
      " 32  month               int64  \n",
      " 33  day                 int64  \n",
      "dtypes: float64(1), int32(1), int64(3), object(29)\n",
      "memory usage: 603.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a25be871",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('grav',axis=1)\n",
    "y = df['grav']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c3ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variable = make_column_selector(dtype_exclude=np.number)\n",
    "tranformer = make_column_transformer((OneHotEncoder(), categorical_variable))\n",
    "\n",
    "model = make_pipeline(tranformer,\n",
    "                      RandomUnderSampler(),\n",
    "                      RandomForestClassifier(random_state=42,verbose=2),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0a7abea",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24200\\180087699.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             trees = Parallel(\n\u001b[0m\u001b[0;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1863\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1865\u001b[0m         \u001b[1;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1792\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    935\u001b[0m         \"\"\"\n\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74eaabc",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16312a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    model.fit(Xconfusion_matrixusion_matrixusion_matrixin, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    N, train_score, val_score = learning_curve(model, X_train, y_train,\n",
    "                                               cv=4, scoring='f1',\n",
    "                                               train_sizes = np.linspace(0.1,1,10))\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(N, train_score.mean(axis=1), label='train_score')\n",
    "    plt.plot(N, valcore.mean(axis=1), label='val_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50320a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.feature_importances_, index= X_train.colums).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97704825",
   "metadata": {},
   "source": [
    "# Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0491b92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af63be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d07bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5cf041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad31ff54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6648ae8d",
   "metadata": {},
   "source": [
    "# Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0869195",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(y_test, grid.best_estimator_.decision_function(X_test))\n",
    "\n",
    "plt.plot(threshold, precision[:-1], label='precision')\n",
    "plt.plot(threshold, recall[:-1], label='recall')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebdcc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_final(model, X, threshold=0):\n",
    "    return model.decision_function(X) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969cfcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_final(grid.best_estimator_, X_test, threshold=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7fed78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35105718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8e4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b80bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e3dc552",
   "metadata": {},
   "source": [
    "<h1>Encodage des variables</h1>\n",
    "\n",
    "Les variables sont encodées une à une afin de pallier à un déficit de mémoire sur certaines machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf585aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['catu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "151fd545",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['sexe'] = le.fit_transform(df['sexe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a5b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['trajet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0286d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.02 \n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['locp'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['locp'] = df['locp'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['locp'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5684540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.02 \n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['actp'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['actp'] = df['actp'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['actp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b0dcdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['etatp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e678a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.01\n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['secuUn'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['secuUn'] = df['secuUn'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['secuUn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84302b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['tranches_ages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f862530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.01\n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['catr'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['catr'] = df['catr'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['catr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a91128e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.01\n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['circ'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['circ'] = df['circ'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['circ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b44dfafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Encoding\n",
    "df['vosp'] = df['vosp'].apply(lambda x: 0 if x == 'Sans objet(0)' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20049a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.05\n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['prof'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['prof'] = df['prof'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['prof'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8df71d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.05\n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['plan'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['plan'] = df['plan'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['plan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d2120bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.02\n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['surf'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['surf'] = df['surf'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['surf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99e9fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.02\n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['infra'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['infra'] = df['infra'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['infra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b0d3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.05\n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['situ'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['situ'] = df['situ'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['situ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a743182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.02\n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['obs'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['obs'] = df['obs'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['obs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d09cc0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuil pour le regroupement des catégories rares\n",
    "#threshold = 0.01\n",
    "\n",
    "# Identifier les catégories rares\n",
    "#rare_categories = df['obsm'].value_counts(normalize=True)\n",
    "#rare_categories = rare_categories[rare_categories < threshold].index\n",
    "\n",
    "# Remplacer les catégories rares par 'Autre'\n",
    "#df['obsm'] = df['obsm'].replace(rare_categories, 'Autre')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['obsm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3d3ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrouper la catégorie \"Non renseigné\" avec \"Aucun\"\n",
    "df['choc'] = df['choc'].replace('Non renseigné', 'Aucun')\n",
    "\n",
    "# Effectuer le one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['choc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbb36ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_encoding = df['manv'].value_counts(normalize=True)\n",
    "df['manv'] = df['manv'].map(frequency_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9e86198",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_encoding = df['catv_Label'].value_counts(normalize=True)\n",
    "df['catv_Label'] = df['catv_Label'].map(frequency_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f89c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_encoding = df['dep'].value_counts(normalize=True)\n",
    "df['dep'] = df['dep'].map(frequency_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9de0087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_encoding = df['com'].value_counts(normalize=True)\n",
    "df['com'] = df['com'].map(frequency_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e260c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['lum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d2d0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['agg'] = df['agg'].replace({'En agglomération': 1, 'Hors agglomération': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "211f7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8c9a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['atm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b6821a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62fc8c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['jour_de_la_semaine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c500cad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2291739, 195)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48037418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['place', 'grav', 'sexe', 'nbv', 'vosp', 'manv', 'catv_Label', 'agg',\n",
       "       'com', 'dep',\n",
       "       ...\n",
       "       'col_Sans collision',\n",
       "       'col_Trois véhicules et plus - collisions multiples',\n",
       "       'col_Trois véhicules et plus – en chaîne',\n",
       "       'jour_de_la_semaine_Dimanche', 'jour_de_la_semaine_Jeudi',\n",
       "       'jour_de_la_semaine_Lundi', 'jour_de_la_semaine_Mardi',\n",
       "       'jour_de_la_semaine_Mercredi', 'jour_de_la_semaine_Samedi',\n",
       "       'jour_de_la_semaine_Vendredi'],\n",
       "      dtype='object', length=195)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0d8d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('grav',axis=1)\n",
    "y = df['grav']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ddade2",
   "metadata": {},
   "source": [
    "<h1>Rééquilibrage de classe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "54347820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Rééchantillonnage de l'ensemble d'entraînement\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5daa1b2",
   "metadata": {},
   "source": [
    "<h1>Réduction de dimension</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801ca54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b86a35b",
   "metadata": {},
   "source": [
    "<h1>Entrainement du modèle</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "481d6910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Indemne': 2.44364813639926, 'Blessé léger': 2.776838562713179, 'Blessé hospitalisé': 4.903570310974648, 'Tué': 37.42378036333945}\n"
     ]
    }
   ],
   "source": [
    "#Utilisation des poids de classe pour l'entrainement du modèle RandomForest\n",
    "# Calculer la fréquence des classes\n",
    "class_counts = y_train.value_counts()\n",
    "class_freq = class_counts / len(y_train)\n",
    "\n",
    "# Inverser la fréquence pour obtenir les poids\n",
    "class_weights = 1 / class_freq\n",
    "\n",
    "# Créer un dictionnaire des poids\n",
    "weights_dict = class_weights.to_dict()\n",
    "print(weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53eb8c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réalisé en 2025.986 secondes\n"
     ]
    }
   ],
   "source": [
    "# Entrainement du modèle\n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "model = RandomForestClassifier(class_weight=weights_dict, n_jobs= -1, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "t1 = time() - t0\n",
    "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089079d",
   "metadata": {},
   "source": [
    "<h1>Calcul des métriques d'évaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee410510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6654725230610802"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1822569f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998942377923622"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0dd481c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réalisé en 7920.002 secondes\n",
      "Classe prédite      Blessé hospitalisé  Blessé léger  Indemne   Tué\n",
      "Classe réelle                                                      \n",
      "Blessé hospitalisé               48208         29870    14444  1122\n",
      "Blessé léger                     24776         99783    40171   312\n",
      "Indemne                          10233         20848   156163   231\n",
      "Tué                               8158          1740     1425   864\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Blessé hospitalisé       0.53      0.51      0.52     93644\n",
      "      Blessé léger       0.66      0.60      0.63    165042\n",
      "           Indemne       0.74      0.83      0.78    187475\n",
      "               Tué       0.34      0.07      0.12     12187\n",
      "\n",
      "          accuracy                           0.67    458348\n",
      "         macro avg       0.57      0.51      0.51    458348\n",
      "      weighted avg       0.65      0.67      0.66    458348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "y_pred = model.predict(X_test)\n",
    "t1 = time() - t0\n",
    "print(\"Réalisé en {} secondes\".format(round(t1,3)))\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite']))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2d6881dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3682037755535663"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "geometric_mean_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a1b34378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5058169767025149"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1458c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 11.7min remaining: 17.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 12.3min finished\n",
      "C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 327, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 918, in _values\n",
      "    return self.values\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 10892, in values\n",
      "    return self._mgr.as_array()\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1599, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1638, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.65 GiB for an array with shape (194, 1833391) and data type object\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 327, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 918, in _values\n",
      "    return self.values\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 10892, in values\n",
      "    return self._mgr.as_array()\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1599, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1646, in _interleave\n",
      "    arr = blk.get_values(dtype)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 228, in get_values\n",
      "    return self.values.astype(_dtype_obj)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.49 GiB for an array with shape (182, 1833391) and data type object\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 327, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 918, in _values\n",
      "    return self.values\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 10892, in values\n",
      "    return self._mgr.as_array()\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1599, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"C:\\Users\\maill\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1638, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.65 GiB for an array with shape (194, 1833392) and data type object\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores ROC AUC OvO pour chaque pli: [nan nan nan nan nan]\n",
      "Moyenne des scores ROC AUC OvO : nan\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "score = cross_val_score(model, X, y, cv=cv, scoring='roc_auc_ovo', verbose=2, n_jobs = -1)\n",
    "\n",
    "print(f\"scores ROC AUC OvO pour chaque pli: {score}\")\n",
    "print(f\"Moyenne des scores ROC AUC OvO : {score.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f1deea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 218.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC score: 0.819\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "steps = [('under', RandomUnderSampler()), ('model', RandomForestClassifier(class_weight=weights_dict, n_jobs= -1, random_state=42))]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='roc_auc_ovo', cv=cv, verbose=2, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('ROC_AUC score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d88a5403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 189.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro score: 0.585\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "steps = [('under', RandomUnderSampler()), ('model', RandomForestClassifier(class_weight=weights_dict, n_jobs= -1, random_state=42))]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, verbose=2, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('f1_micro score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2401fc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6291227566841988\n",
      "0.5835718711546685\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.fit(X_train, y_train).score(X_train, y_train))\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
