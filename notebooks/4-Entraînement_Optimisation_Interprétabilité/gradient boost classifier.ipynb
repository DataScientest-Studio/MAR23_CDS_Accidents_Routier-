{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc1d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c26872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\maill\\fusion3_clean.csv\", low_memory=False)\n",
    "df.drop(['Unnamed: 0', 'num_acc'],axis=1, inplace=True)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9137de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763b5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation de la variable cible y avant l'encodage\n",
    "y = df['grav']\n",
    "\n",
    "X = df.drop('grav', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7a42369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de l'ensemble d'entrainement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17436459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['place', 'catu', 'sexe', 'trajet', 'locp', 'actp', 'etatp', 'secuUn',\n",
       "       'tranches_ages', 'catr', 'circ', 'nbv', 'vosp', 'prof', 'plan', 'surf',\n",
       "       'infra', 'situ', 'obs', 'obsm', 'choc', 'manv', 'catv_Label', 'lum',\n",
       "       'agg', 'int', 'atm', 'col', 'com', 'dep', 'jour_de_la_semaine',\n",
       "       'heure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a381de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train:\n",
    "    # Calculer la fréquence de chaque catégorie\n",
    "    frequency_encoding = X_train[col].value_counts(normalize=True)\n",
    "\n",
    "    # Remplacer chaque catégorie par sa fréquence\n",
    "    X_train[col] = X_train[col].map(frequency_encoding)\n",
    "    \n",
    "for col in X_test:\n",
    "    # Calculer la fréquence de chaque catégorie\n",
    "    frequency_encoding = X_test[col].value_counts(normalize=True)\n",
    "\n",
    "    # Remplacer chaque catégorie par sa fréquence\n",
    "    X_test[col] = X_test[col].map(frequency_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54fcc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Étape 1 : Calculer les poids des classes\n",
    "classes = ['Blessé léger', 'Indemne', 'Blessé hospitalisé', 'Tué']\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "\n",
    "# Mapping des noms de classe aux poids\n",
    "class_weight_dict = {class_label: weight for class_label, weight in zip(classes, class_weights)}\n",
    "\n",
    "# Étape 2 : Créer un tableau de poids d'échantillons\n",
    "sample_weights = np.array([class_weight_dict[label] for label in y_train])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c866a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réalisé en 51933.872 secondes\n"
     ]
    }
   ],
   "source": [
    "# Entrainement du modèle\n",
    "from time import time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = GradientBoostingClassifier(max_depth=25, n_iter_no_change=10, validation_fraction=0.1, tol=0.01)\n",
    "clf.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "t1 = time() - t0\n",
    "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad6f0cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe prédite      Blessé hospitalisé  Blessé léger  Indemne   Tué\n",
      "Classe réelle                                                      \n",
      "Blessé hospitalisé               46072         28785    12651  6136\n",
      "Blessé léger                     31652         93353    37306  2731\n",
      "Indemne                          13499         27617   144456  1903\n",
      "Tué                               6212          2243     1206  2526\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Blessé hospitalisé       0.47      0.49      0.48     93644\n",
      "      Blessé léger       0.61      0.57      0.59    165042\n",
      "           Indemne       0.74      0.77      0.75    187475\n",
      "               Tué       0.19      0.21      0.20     12187\n",
      "\n",
      "          accuracy                           0.62    458348\n",
      "         macro avg       0.50      0.51      0.51    458348\n",
      "      weighted avg       0.62      0.62      0.62    458348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite']))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fb823ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score micro: 0.6248680042238648\n"
     ]
    }
   ],
   "source": [
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f'F1-Score micro: {f1_micro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a732204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
